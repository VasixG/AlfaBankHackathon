{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h3\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and preprocessing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading Resources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n"
     ]
    }
   ],
   "source": [
    "target = pd.read_csv('data/target_hakaton_spb.csv').fillna(0)\n",
    "target.rename(columns={'lat_h3': 'lat', 'lon_h3': 'lon'}, inplace=True)\n",
    "target_only_count = target.groupby('geo_h3_10').atm_cnt.sum().to_frame('atm_cnt').merge(\n",
    "    target[['geo_h3_10', 'lat', 'lon', 'city']], on='geo_h3_10', how='left').drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_amenity = pd.read_csv('data/train/osm_amenity.csv').drop_duplicates(subset='geo_h3_10', inplace=True)\n",
    "osm_stops = pd.read_csv('data/train/osm_stops.csv').drop_duplicates()\n",
    "population = pd.read_csv('data/train/rosstat_population_all_cities.csv').drop_duplicates()\n",
    "iso_walk = pd.read_csv('data/train/isochrones_walk_dataset.csv').drop_duplicates()\n",
    "iso_drive = pd.read_csv('data/train/isochrones_drive_dataset.csv').drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tram_stops = osm_stops[osm_stops['type'] == 'tram_stop'].groupby(by='geo_h3_10').count()['type'].to_frame(\n",
    "    'n_tram_stops')\n",
    "n_subway_entrances = osm_stops[osm_stops['type'] == 'subway_entrance'].groupby(by='geo_h3_10').count()['type'].to_frame(\n",
    "    'n_subway_entrances')\n",
    "n_bus_stops = osm_stops[osm_stops['type'] == 'bus_stop'].groupby(by='geo_h3_10').count()['type'].to_frame('n_bus_stops')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging everything into one table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(target_only_count, population, how='outer', on=['geo_h3_10', 'city', 'lat', 'lon'])\n",
    "df = pd.merge(df, osm_amenity, how='outer', on=['geo_h3_10', 'city', 'lat', 'lon'])\n",
    "df = pd.merge(df, n_bus_stops, how='outer', on='geo_h3_10')\n",
    "df = pd.merge(df, n_tram_stops, how='outer', on='geo_h3_10')\n",
    "df = pd.merge(df, n_subway_entrances, how='outer', on='geo_h3_10')\n",
    "df = pd.merge(df, osm_stops[['geo_h3_10', 'city']].drop_duplicates(), how='outer', on=['geo_h3_10', 'city'])\n",
    "\n",
    "df.drop_duplicates(subset='geo_h3_10', inplace=True)\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.set_index('geo_h3_10', inplace=True)\n",
    "\n",
    "subway_entrances = df[df['n_subway_entrances'] > 0].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Counting distance to the nearest subway entrance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_haversine(point_1: tuple, point_2: tuple):\n",
    "    d_earth = 2.0 * 6372.8\n",
    "    lat1, long1 = tuple(radians(c) for c in point_1)\n",
    "    lat2, long2 = tuple(radians(c) for c in point_2)\n",
    "    d = sin((lat2 - lat1) / 2.0) ** 2.0 + cos(lat1) * cos(lat2) * sin(\n",
    "        (long2 - long1) / 2.0) ** 2.0\n",
    "    return d_earth * asin(d ** 0.5)\n",
    "\n",
    "\n",
    "def find_nearest(point_1, points):\n",
    "    dists = [distance_haversine(point_1, p) for p in points]\n",
    "    dist = min(dists)\n",
    "    return dist\n",
    "\n",
    "\n",
    "subway_entrances_geo = [h3.h3_to_geo(tag) for tag in subway_entrances]\n",
    "\n",
    "\n",
    "def find_dist_from_h3(h3tag):\n",
    "    lat, lon = h3.h3_to_geo(h3tag)\n",
    "    return find_nearest((lat, lon), subway_entrances_geo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49875/49875 [00:14<00:00, 3388.41it/s]\n"
     ]
    }
   ],
   "source": [
    "df['dist_to_subway'] = [find_dist_from_h3(x) for x in tqdm(df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Workarounding missing latitude and longitude"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49875/49875 [00:00<00:00, 819411.78it/s]\n",
      "100%|██████████| 49875/49875 [00:00<00:00, 626697.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df['lat'] = [h3.h3_to_geo(x)[0] for x in tqdm(df.index)]\n",
    "df['lon'] = [h3.h3_to_geo(x)[1] for x in tqdm(df.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv('prikol.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# READ CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = pd.read_csv('prikol.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining all business parameters into one parameter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "df['businesses'] = df['Автозапчасти для иномарок'] + df['Авторемонт и техобслуживание (СТО)'] + df[\n",
    "    'Алкогольные напитки'] + df['Аптеки'] + df['Банки'] + df['Быстрое питание'] + df['Доставка готовых блюд'] + df[\n",
    "                       'Женская одежда'] + df['Кафе'] + df['Косметика / Парфюмерия'] + df['Ногтевые студии'] + df[\n",
    "                       'Овощи / Фрукты'] + df['Парикмахерские'] + df['Платёжные терминалы'] + df['Постаматы'] + df[\n",
    "                       'Продуктовые магазины'] + df['Пункты выдачи интернет-заказов'] + df['Рестораны'] + df[\n",
    "                       'Страхование'] + df['Супермаркеты'] + df['Цветы'] + df['Шиномонтаж']\n",
    "\n",
    "df.drop(inplace=True, axis=1, columns=['Автозапчасти для иномарок', 'Авторемонт и техобслуживание (СТО)',\n",
    "                                       'Алкогольные напитки', 'Аптеки', 'Банки', 'Быстрое питание',\n",
    "                                       'Доставка готовых блюд', 'Женская одежда', 'Кафе',\n",
    "                                       'Косметика / Парфюмерия', 'Ногтевые студии', 'Овощи / Фрукты',\n",
    "                                       'Парикмахерские', 'Платёжные терминалы', 'Постаматы',\n",
    "                                       'Продуктовые магазины', 'Пункты выдачи интернет-заказов', 'Рестораны',\n",
    "                                       'Страхование', 'Супермаркеты', 'Цветы', 'Шиномонтаж'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For each hex getting data about nearby hexes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "def get_nearby_information_for_hexes(sub_df: pd.DataFrame, df: pd.DataFrame, dist: float) -> pd.DataFrame:\n",
    "    df2 = sub_df.copy(deep=True)\n",
    "    df2['nearby_population'] = 0\n",
    "    df2['nearby_n_bus_stops'] = 0\n",
    "    df2['nearby_n_tram_stops'] = 0\n",
    "    df2['nearby_n_subway_entrances'] = 0\n",
    "    df2['nearby_businesses'] = 0\n",
    "    df2['nearby_atm_cnt'] = 0\n",
    "    for x in tqdm(sub_df.index.unique()):\n",
    "        gx = h3.h3_to_geo(x)\n",
    "        nearby = []\n",
    "        for y in df.index.unique():\n",
    "            gy = h3.h3_to_geo(y)\n",
    "            if x != y and distance_haversine(gx, gy) <= dist:\n",
    "                nearby.append(y)\n",
    "        for y in nearby:\n",
    "            df2.loc[x, 'nearby_population'] += df.loc[y, 'population']\n",
    "            df2.loc[x, 'nearby_n_bus_stops'] += df.loc[y, 'n_bus_stops']\n",
    "            df2.loc[x, 'nearby_n_tram_stops'] += df.loc[y, 'n_tram_stops']\n",
    "            df2.loc[x, 'nearby_n_subway_entrances'] += df.loc[y, 'n_subway_entrances']\n",
    "            df2.loc[x, 'nearby_businesses'] += df.loc[y, 'businesses']\n",
    "            df2.loc[x, 'nearby_atm_cnt'] += df.loc[y, 'atm_cnt']\n",
    "    return df2\n",
    "\n",
    "\n",
    "def get_nearby_information_for_radius(x: str, dist1: float, dist2: float, df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    gx = h3.h3_to_geo(x)\n",
    "    nearby = []\n",
    "    for y in df.index.unique():\n",
    "        gy = h3.h3_to_geo(y)\n",
    "        if x != y and distance_haversine(gx, gy) <= dist1:\n",
    "            nearby.append(y)\n",
    "    nearby.append(x)\n",
    "\n",
    "    sub_df = df[df.index.isin(nearby)].copy(deep=True)\n",
    "\n",
    "    return get_nearby_information_for_hexes(sub_df, df, dist2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the best location using recursive function with ML"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "def get_best_hex_from_df2(df2: pd.DataFrame):\n",
    "    df2 = df2.copy(deep=True)\n",
    "    df2.reset_index(inplace=True)\n",
    "    df2 = df2.drop(['lat', 'lon'], axis=1)\n",
    "    df2 = df2[df2.nearby_population > 0]\n",
    "\n",
    "    X = df2[['geo_h3_10', 'dist_to_subway', 'nearby_population', 'nearby_n_bus_stops', 'nearby_n_tram_stops',\n",
    "             'nearby_businesses']]\n",
    "    # print(X)\n",
    "\n",
    "    if X.empty:\n",
    "        return None\n",
    "\n",
    "\n",
    "    y = df2['nearby_atm_cnt']\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.drop('geo_h3_10', axis=1), y, test_size=0.33, random_state=42)\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred = lr.predict(X=X_test).round()\n",
    "\n",
    "\n",
    "    data = {'model': pred,\n",
    "            'true': y_test,\n",
    "            'error': abs(pred - y_test)}\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    if df[(df.error >= 1) & (df.true == 0)].sort_values('model', ascending=False).model.empty:\n",
    "        return None\n",
    "\n",
    "    ind = df[(df.error >= 1) & (df.true == 0)].sort_values('model', ascending=False).model.index[0]\n",
    "\n",
    "    best = X.geo_h3_10[ind]\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def MaChInE_LeArNiNg(df2: pd.DataFrame, dist: float):\n",
    "    best_hex = get_best_hex_from_df2(df2)\n",
    "    if best_hex is None:\n",
    "        return None\n",
    "\n",
    "    df2 = get_nearby_information_for_radius(best_hex, dist, dist - 0.2, df2)\n",
    "    res = MaChInE_LeArNiNg(df2, dist - 0.2)\n",
    "\n",
    "    if res is not None:\n",
    "        return res\n",
    "    return best_hex\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19101/19101 [20:34<00:00, 15.47it/s]\n"
     ]
    }
   ],
   "source": [
    "df2_spb = get_nearby_information_for_hexes(df[df.city == \"Санкт-Петербург\"], df[df.city == \"Санкт-Петербург\"], 0.6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:02<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 439.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "(60.05330310392827, 30.341160511496316)"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_place = MaChInE_LeArNiNg(df2_spb, 0.6)\n",
    "h3.h3_to_geo(best_place)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f167b85c76257b9945e8d25a58d5d9a0e9f372b7bcb7bab872ccec63e04fb34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}